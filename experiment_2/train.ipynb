{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train prediction models for grating orientation \n",
    "* convolutional neural network, input features_SA and features RA of size (n_pins, n_pins) representing firing rate on an n_pins x n_pins square array                \n",
    "* training data concatenated over grating stimuli of periods 0-5mm (stimuli 1 to 8) and physical orientation angle of the stimulus (90, 180, 270, 36)\n",
    "* only the yaw relative to the grating orientation is kept as a label; range (-90,90) rescaled to (0,1)\n",
    "* i.e. prediction independent of grating period and physical orientation of the stimulus relative to the robot\n",
    "\n",
    "To run, first edit dir_data to path where data is stored; experiment_2/process in this directory should be run first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "import numpy as np\n",
    "\n",
    "def open_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = os.environ[\"DATAPATH\"] + r\"/open/afferents-tactile-gratings-jrsi2022/experiment_2\"\n",
    "n_stimuli = 8\n",
    "n_angles = 4\n",
    "stimuli = [f'{i}' for i in range(n_stimuli)] # do not include smooth (0) stimulus\n",
    "angles = [f'{90*a}' for a in range(n_angles)]\n",
    "n_pins = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SA = [[open_obj(dir_data + rf\"/processed/train_data/{stimuli[i]}/{angles[j]}/X_train_sa\") for j in range(n_angles)] for i in range(n_stimuli)]\n",
    "y_train_SA = [[open_obj(dir_data + rf\"/processed/train_data/{stimuli[i]}/{angles[j]}/y_train_sa\") for j in range(n_angles)] for i in range(n_stimuli)]\n",
    "X_val_SA = [[open_obj(dir_data + rf\"/processed/train_data/{stimuli[i]}/{angles[j]}/X_val_sa\") for j in range(n_angles)] for i in range(n_stimuli)]\n",
    "y_val_SA = [[open_obj(dir_data + rf\"/processed/train_data/{stimuli[i]}/{angles[j]}/y_val_sa\") for j in range(n_angles)] for i in range(n_stimuli)]\n",
    "\n",
    "X_train_RA = [[open_obj(dir_data + rf\"/processed/train_data/{stimuli[i]}/{angles[j]}/X_train_ra\") for j in range(n_angles)] for i in range(n_stimuli)]\n",
    "y_train_RA = [[open_obj(dir_data + rf\"/processed/train_data/{stimuli[i]}/{angles[j]}/y_train_ra\") for j in range(n_angles)] for i in range(n_stimuli)]\n",
    "X_val_RA = [[open_obj(dir_data + rf\"/processed/train_data/{stimuli[i]}/{angles[j]}/X_val_ra\") for j in range(n_angles)] for i in range(n_stimuli)]\n",
    "y_val_RA = [[open_obj(dir_data + rf\"/processed/train_data/{stimuli[i]}/{angles[j]}/y_val_ra\") for j in range(n_angles)] for i in range(n_stimuli)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SA = np.reshape(np.stack(X_train_SA), (-1,n_pins,n_pins))\n",
    "y_train_SA = (np.reshape(np.stack(y_train_SA), (-1)) + 90)/180\n",
    "X_val_SA = np.reshape(np.stack(X_val_SA), (-1,n_pins,n_pins))\n",
    "y_val_SA = (np.reshape(np.stack(y_val_SA), (-1)) + 90)/180\n",
    "\n",
    "X_train_RA = np.reshape(np.stack(X_train_RA), (-1,n_pins,n_pins))\n",
    "y_train_RA = (np.reshape(np.stack(y_train_RA), (-1)) + 90)/180\n",
    "X_val_RA = np.reshape(np.stack(X_val_RA), (-1,n_pins,n_pins))\n",
    "y_val_RA = (np.reshape(np.stack(y_val_RA), (-1)) + 90)/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session, clear_session\n",
    "from keras import optimizers, regularizers, callbacks\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(X_train, y_train, X_val, y_val, es, cp):\n",
    "    \n",
    "    clear_session()\n",
    "        \n",
    "    config = tf.ConfigProto(gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8))\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    set_session(session)\n",
    "    \n",
    "    seed(1)\n",
    "    set_random_seed(2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding=\"same\", input_shape=(n_pins,n_pins,1)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding=\"valid\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer = optimizers.rmsprop(lr=1e-4), metrics=['mae'])\n",
    "    model.fit(np.expand_dims(X_train, axis=3), y_train, validation_data=(np.expand_dims(X_val, axis=3), y_val), epochs=100, batch_size=32, shuffle=True, callbacks=[cp,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5984 samples, validate on 2016 samples\n",
      "Epoch 1/500\n",
      "5984/5984 [==============================] - 2s 407us/step - loss: 1.4325 - mae: 0.7793 - val_loss: 0.8689 - val_mae: 0.6016\n",
      "Epoch 2/500\n",
      "5984/5984 [==============================] - 2s 274us/step - loss: 1.0917 - mae: 0.6457 - val_loss: 0.5963 - val_mae: 0.3570\n",
      "Epoch 3/500\n",
      "5984/5984 [==============================] - 2s 273us/step - loss: 0.9571 - mae: 0.5810 - val_loss: 0.5248 - val_mae: 0.2981\n",
      "Epoch 4/500\n",
      "5984/5984 [==============================] - 2s 278us/step - loss: 0.8305 - mae: 0.5224 - val_loss: 0.5210 - val_mae: 0.3105\n",
      "Epoch 5/500\n",
      "5984/5984 [==============================] - 2s 273us/step - loss: 0.7777 - mae: 0.4947 - val_loss: 0.4972 - val_mae: 0.3016\n",
      "Epoch 6/500\n",
      "5984/5984 [==============================] - 2s 278us/step - loss: 0.7094 - mae: 0.4610 - val_loss: 0.4519 - val_mae: 0.2768\n",
      "Epoch 7/500\n",
      "5984/5984 [==============================] - 2s 297us/step - loss: 0.6612 - mae: 0.4407 - val_loss: 0.4131 - val_mae: 0.2515\n",
      "Epoch 8/500\n",
      "5984/5984 [==============================] - 2s 304us/step - loss: 0.6178 - mae: 0.4270 - val_loss: 0.4126 - val_mae: 0.2710\n",
      "Epoch 9/500\n",
      "5984/5984 [==============================] - 2s 294us/step - loss: 0.5678 - mae: 0.4066 - val_loss: 0.3781 - val_mae: 0.2491\n",
      "Epoch 10/500\n",
      "5984/5984 [==============================] - 2s 320us/step - loss: 0.5392 - mae: 0.3973 - val_loss: 0.3580 - val_mae: 0.2501\n",
      "Epoch 11/500\n",
      "5984/5984 [==============================] - 2s 316us/step - loss: 0.5114 - mae: 0.3949 - val_loss: 0.3444 - val_mae: 0.2541\n",
      "Epoch 12/500\n",
      "5984/5984 [==============================] - 2s 303us/step - loss: 0.4796 - mae: 0.3843 - val_loss: 0.3239 - val_mae: 0.2530\n",
      "Epoch 13/500\n",
      "5984/5984 [==============================] - 2s 303us/step - loss: 0.4402 - mae: 0.3650 - val_loss: 0.3104 - val_mae: 0.2580\n",
      "Epoch 14/500\n",
      "5984/5984 [==============================] - 2s 314us/step - loss: 0.4187 - mae: 0.3614 - val_loss: 0.2891 - val_mae: 0.2508\n",
      "Epoch 15/500\n",
      "5984/5984 [==============================] - 2s 291us/step - loss: 0.3893 - mae: 0.3511 - val_loss: 0.2748 - val_mae: 0.2557\n",
      "Epoch 16/500\n",
      "5984/5984 [==============================] - 2s 310us/step - loss: 0.3617 - mae: 0.3402 - val_loss: 0.2549 - val_mae: 0.2457\n",
      "Epoch 17/500\n",
      "5984/5984 [==============================] - 2s 349us/step - loss: 0.3421 - mae: 0.3361 - val_loss: 0.2432 - val_mae: 0.2496\n",
      "Epoch 18/500\n",
      "5984/5984 [==============================] - 2s 294us/step - loss: 0.3188 - mae: 0.3253 - val_loss: 0.2304 - val_mae: 0.2473\n",
      "Epoch 19/500\n",
      "5984/5984 [==============================] - 2s 315us/step - loss: 0.2938 - mae: 0.3142 - val_loss: 0.2170 - val_mae: 0.2476\n",
      "Epoch 20/500\n",
      "5984/5984 [==============================] - 2s 295us/step - loss: 0.2819 - mae: 0.3157 - val_loss: 0.2074 - val_mae: 0.2491\n",
      "Epoch 21/500\n",
      "5984/5984 [==============================] - 2s 316us/step - loss: 0.2655 - mae: 0.3143 - val_loss: 0.1948 - val_mae: 0.2481\n",
      "Epoch 22/500\n",
      "5984/5984 [==============================] - 2s 296us/step - loss: 0.2495 - mae: 0.3081 - val_loss: 0.1862 - val_mae: 0.2472\n",
      "Epoch 23/500\n",
      "5984/5984 [==============================] - 2s 300us/step - loss: 0.2380 - mae: 0.3062 - val_loss: 0.1777 - val_mae: 0.2479\n",
      "Epoch 24/500\n",
      "5984/5984 [==============================] - 2s 289us/step - loss: 0.2253 - mae: 0.3016 - val_loss: 0.1722 - val_mae: 0.2506\n",
      "Epoch 25/500\n",
      "5984/5984 [==============================] - 2s 322us/step - loss: 0.2113 - mae: 0.2949 - val_loss: 0.1639 - val_mae: 0.2471\n",
      "Epoch 26/500\n",
      "5984/5984 [==============================] - 2s 315us/step - loss: 0.2041 - mae: 0.2932 - val_loss: 0.1580 - val_mae: 0.2478\n",
      "Epoch 27/500\n",
      "5984/5984 [==============================] - 2s 295us/step - loss: 0.1910 - mae: 0.2865 - val_loss: 0.1540 - val_mae: 0.2505\n",
      "Epoch 28/500\n",
      "5984/5984 [==============================] - 2s 296us/step - loss: 0.1860 - mae: 0.2851 - val_loss: 0.1462 - val_mae: 0.2456\n",
      "Epoch 29/500\n",
      "5984/5984 [==============================] - 2s 300us/step - loss: 0.1777 - mae: 0.2831 - val_loss: 0.1426 - val_mae: 0.2468\n",
      "Epoch 30/500\n",
      "5984/5984 [==============================] - 2s 297us/step - loss: 0.1682 - mae: 0.2762 - val_loss: 0.1338 - val_mae: 0.2372\n",
      "Epoch 31/500\n",
      "5984/5984 [==============================] - 2s 310us/step - loss: 0.1573 - mae: 0.2667 - val_loss: 0.1240 - val_mae: 0.2243\n",
      "Epoch 32/500\n",
      "5984/5984 [==============================] - 2s 345us/step - loss: 0.1497 - mae: 0.2586 - val_loss: 0.1186 - val_mae: 0.2177\n",
      "Epoch 33/500\n",
      "5984/5984 [==============================] - 2s 307us/step - loss: 0.1415 - mae: 0.2521 - val_loss: 0.1120 - val_mae: 0.2130\n",
      "Epoch 34/500\n",
      "5984/5984 [==============================] - 2s 330us/step - loss: 0.1355 - mae: 0.2480 - val_loss: 0.1128 - val_mae: 0.2186\n",
      "Epoch 35/500\n",
      "5984/5984 [==============================] - 2s 300us/step - loss: 0.1281 - mae: 0.2418 - val_loss: 0.1047 - val_mae: 0.2093\n",
      "Epoch 36/500\n",
      "5984/5984 [==============================] - 2s 319us/step - loss: 0.1246 - mae: 0.2397 - val_loss: 0.1011 - val_mae: 0.2062\n",
      "Epoch 37/500\n",
      "5984/5984 [==============================] - 2s 333us/step - loss: 0.1182 - mae: 0.2331 - val_loss: 0.1067 - val_mae: 0.2189\n",
      "Epoch 38/500\n",
      "5984/5984 [==============================] - 2s 312us/step - loss: 0.1143 - mae: 0.2304 - val_loss: 0.1077 - val_mae: 0.2249\n",
      "Epoch 39/500\n",
      "5984/5984 [==============================] - 2s 308us/step - loss: 0.1112 - mae: 0.2288 - val_loss: 0.0948 - val_mae: 0.2028\n",
      "Epoch 40/500\n",
      "5984/5984 [==============================] - 2s 316us/step - loss: 0.1075 - mae: 0.2245 - val_loss: 0.0906 - val_mae: 0.2006\n",
      "Epoch 41/500\n",
      "5984/5984 [==============================] - 2s 306us/step - loss: 0.1011 - mae: 0.2192 - val_loss: 0.0849 - val_mae: 0.1920\n",
      "Epoch 42/500\n",
      "5984/5984 [==============================] - 2s 305us/step - loss: 0.0969 - mae: 0.2138 - val_loss: 0.0856 - val_mae: 0.1958\n",
      "Epoch 43/500\n",
      "5984/5984 [==============================] - 2s 306us/step - loss: 0.0952 - mae: 0.2138 - val_loss: 0.0878 - val_mae: 0.1987\n",
      "Epoch 44/500\n",
      "5984/5984 [==============================] - 2s 298us/step - loss: 0.0920 - mae: 0.2114 - val_loss: 0.0789 - val_mae: 0.1870\n",
      "Epoch 45/500\n",
      "5984/5984 [==============================] - 3s 529us/step - loss: 0.0887 - mae: 0.2066 - val_loss: 0.1007 - val_mae: 0.2267\n",
      "Epoch 46/500\n",
      "5984/5984 [==============================] - 6s 1ms/step - loss: 0.0856 - mae: 0.2029 - val_loss: 0.0771 - val_mae: 0.1869\n",
      "Epoch 47/500\n",
      "5984/5984 [==============================] - 5s 777us/step - loss: 0.0832 - mae: 0.2006 - val_loss: 0.0723 - val_mae: 0.1808\n",
      "Epoch 48/500\n",
      "5984/5984 [==============================] - 2s 367us/step - loss: 0.0796 - mae: 0.1956 - val_loss: 0.0703 - val_mae: 0.1790\n",
      "Epoch 49/500\n",
      "5984/5984 [==============================] - 2s 383us/step - loss: 0.0773 - mae: 0.1938 - val_loss: 0.0716 - val_mae: 0.1845\n",
      "Epoch 50/500\n",
      "5984/5984 [==============================] - 2s 344us/step - loss: 0.0767 - mae: 0.1936 - val_loss: 0.0918 - val_mae: 0.2176\n",
      "Epoch 51/500\n",
      "5984/5984 [==============================] - 2s 311us/step - loss: 0.0742 - mae: 0.1913 - val_loss: 0.0760 - val_mae: 0.1937\n",
      "Epoch 52/500\n",
      "5984/5984 [==============================] - 2s 307us/step - loss: 0.0732 - mae: 0.1912 - val_loss: 0.0711 - val_mae: 0.1873\n",
      "Epoch 53/500\n",
      "5984/5984 [==============================] - 2s 310us/step - loss: 0.0702 - mae: 0.1873 - val_loss: 0.0741 - val_mae: 0.1936\n",
      "Epoch 54/500\n",
      "5984/5984 [==============================] - 2s 312us/step - loss: 0.0686 - mae: 0.1846 - val_loss: 0.0645 - val_mae: 0.1765\n",
      "Epoch 55/500\n",
      "5984/5984 [==============================] - 2s 345us/step - loss: 0.0677 - mae: 0.1841 - val_loss: 0.0908 - val_mae: 0.2212\n",
      "Epoch 56/500\n",
      "5984/5984 [==============================] - 2s 345us/step - loss: 0.0656 - mae: 0.1806 - val_loss: 0.0651 - val_mae: 0.1749\n",
      "Epoch 57/500\n",
      "5984/5984 [==============================] - 2s 386us/step - loss: 0.0643 - mae: 0.1796 - val_loss: 0.0705 - val_mae: 0.1929\n",
      "Epoch 58/500\n",
      "5984/5984 [==============================] - 2s 371us/step - loss: 0.0624 - mae: 0.1766 - val_loss: 0.0602 - val_mae: 0.1722\n",
      "Epoch 59/500\n",
      "5984/5984 [==============================] - 2s 373us/step - loss: 0.0619 - mae: 0.1765 - val_loss: 0.0631 - val_mae: 0.1788\n",
      "Epoch 60/500\n",
      "5984/5984 [==============================] - 2s 395us/step - loss: 0.0599 - mae: 0.1741 - val_loss: 0.1191 - val_mae: 0.2641\n",
      "Epoch 61/500\n",
      "5984/5984 [==============================] - 3s 431us/step - loss: 0.0596 - mae: 0.1751 - val_loss: 0.0592 - val_mae: 0.1742\n",
      "Epoch 62/500\n",
      "5984/5984 [==============================] - 2s 415us/step - loss: 0.0594 - mae: 0.1748 - val_loss: 0.1111 - val_mae: 0.2542\n",
      "Epoch 63/500\n",
      "5984/5984 [==============================] - 2s 343us/step - loss: 0.0564 - mae: 0.1700 - val_loss: 0.0601 - val_mae: 0.1707\n",
      "Epoch 64/500\n",
      "5984/5984 [==============================] - 2s 372us/step - loss: 0.0552 - mae: 0.1689 - val_loss: 0.0899 - val_mae: 0.2277\n",
      "Epoch 65/500\n",
      "5984/5984 [==============================] - 2s 355us/step - loss: 0.0554 - mae: 0.1694 - val_loss: 0.0560 - val_mae: 0.1676\n",
      "Epoch 66/500\n",
      "5984/5984 [==============================] - 2s 404us/step - loss: 0.0546 - mae: 0.1674 - val_loss: 0.0627 - val_mae: 0.1775\n",
      "Epoch 67/500\n",
      "5984/5984 [==============================] - 2s 321us/step - loss: 0.0530 - mae: 0.1652 - val_loss: 0.1025 - val_mae: 0.2442\n",
      "Epoch 68/500\n",
      "5984/5984 [==============================] - 2s 306us/step - loss: 0.0536 - mae: 0.1670 - val_loss: 0.0544 - val_mae: 0.1690\n",
      "Epoch 69/500\n",
      "5984/5984 [==============================] - 2s 308us/step - loss: 0.0520 - mae: 0.1648 - val_loss: 0.0660 - val_mae: 0.1868\n",
      "Epoch 70/500\n",
      "5984/5984 [==============================] - 2s 303us/step - loss: 0.0505 - mae: 0.1612 - val_loss: 0.0565 - val_mae: 0.1690\n",
      "Epoch 71/500\n",
      "5984/5984 [==============================] - 2s 327us/step - loss: 0.0503 - mae: 0.1615 - val_loss: 0.0894 - val_mae: 0.2267\n",
      "Epoch 72/500\n",
      "5984/5984 [==============================] - 2s 339us/step - loss: 0.0496 - mae: 0.1621 - val_loss: 0.0567 - val_mae: 0.1664\n",
      "Epoch 73/500\n",
      "5984/5984 [==============================] - 2s 360us/step - loss: 0.0488 - mae: 0.1597 - val_loss: 0.0599 - val_mae: 0.1801\n",
      "Epoch 74/500\n",
      "5984/5984 [==============================] - 2s 319us/step - loss: 0.0492 - mae: 0.1599 - val_loss: 0.0545 - val_mae: 0.1667\n",
      "Epoch 75/500\n",
      "5984/5984 [==============================] - 2s 321us/step - loss: 0.0482 - mae: 0.1596 - val_loss: 0.0580 - val_mae: 0.1720\n",
      "Epoch 76/500\n",
      "5984/5984 [==============================] - 2s 326us/step - loss: 0.0469 - mae: 0.1562 - val_loss: 0.0535 - val_mae: 0.1644\n",
      "Epoch 77/500\n",
      "5984/5984 [==============================] - 2s 407us/step - loss: 0.0476 - mae: 0.1582 - val_loss: 0.0823 - val_mae: 0.2135\n",
      "Epoch 78/500\n",
      "5984/5984 [==============================] - 2s 334us/step - loss: 0.0461 - mae: 0.1553 - val_loss: 0.0538 - val_mae: 0.1694\n",
      "Epoch 79/500\n",
      "5984/5984 [==============================] - 2s 312us/step - loss: 0.0456 - mae: 0.1552 - val_loss: 0.0644 - val_mae: 0.1868\n",
      "Epoch 80/500\n",
      "5984/5984 [==============================] - 2s 309us/step - loss: 0.0449 - mae: 0.1528 - val_loss: 0.0684 - val_mae: 0.1858\n",
      "Epoch 81/500\n",
      "5984/5984 [==============================] - 2s 304us/step - loss: 0.0458 - mae: 0.1542 - val_loss: 0.0476 - val_mae: 0.1603\n",
      "Epoch 82/500\n",
      "5984/5984 [==============================] - 2s 319us/step - loss: 0.0443 - mae: 0.1520 - val_loss: 0.0590 - val_mae: 0.1763\n",
      "Epoch 83/500\n",
      "5984/5984 [==============================] - 2s 317us/step - loss: 0.0436 - mae: 0.1517 - val_loss: 0.0540 - val_mae: 0.1682\n",
      "Epoch 84/500\n",
      "5984/5984 [==============================] - 2s 310us/step - loss: 0.0434 - mae: 0.1505 - val_loss: 0.0551 - val_mae: 0.1685\n",
      "Epoch 85/500\n",
      "5984/5984 [==============================] - 2s 307us/step - loss: 0.0427 - mae: 0.1491 - val_loss: 0.0537 - val_mae: 0.1637\n",
      "Epoch 86/500\n",
      "5984/5984 [==============================] - 2s 306us/step - loss: 0.0429 - mae: 0.1496 - val_loss: 0.0481 - val_mae: 0.1560\n",
      "Epoch 87/500\n",
      "5984/5984 [==============================] - 2s 327us/step - loss: 0.0413 - mae: 0.1466 - val_loss: 0.0565 - val_mae: 0.1675\n",
      "Epoch 88/500\n",
      "5984/5984 [==============================] - 2s 325us/step - loss: 0.0416 - mae: 0.1473 - val_loss: 0.0500 - val_mae: 0.1573\n",
      "Epoch 89/500\n",
      "5984/5984 [==============================] - 2s 353us/step - loss: 0.0402 - mae: 0.1444 - val_loss: 0.0676 - val_mae: 0.1914\n",
      "Epoch 90/500\n",
      "5984/5984 [==============================] - 2s 361us/step - loss: 0.0403 - mae: 0.1455 - val_loss: 0.0478 - val_mae: 0.1528\n",
      "Epoch 91/500\n",
      "5984/5984 [==============================] - 3s 425us/step - loss: 0.0399 - mae: 0.1439 - val_loss: 0.0538 - val_mae: 0.1695\n",
      "Epoch 92/500\n",
      "5984/5984 [==============================] - 2s 346us/step - loss: 0.0390 - mae: 0.1412 - val_loss: 0.0588 - val_mae: 0.1777\n",
      "Epoch 93/500\n",
      "5984/5984 [==============================] - 2s 312us/step - loss: 0.0408 - mae: 0.1461 - val_loss: 0.0482 - val_mae: 0.1578\n",
      "Epoch 94/500\n",
      "5984/5984 [==============================] - 2s 317us/step - loss: 0.0390 - mae: 0.1422 - val_loss: 0.0701 - val_mae: 0.1962\n",
      "Epoch 95/500\n",
      "5984/5984 [==============================] - 2s 313us/step - loss: 0.0388 - mae: 0.1423 - val_loss: 0.0608 - val_mae: 0.1719\n",
      "Epoch 96/500\n",
      "5984/5984 [==============================] - 2s 313us/step - loss: 0.0384 - mae: 0.1411 - val_loss: 0.0478 - val_mae: 0.1539\n",
      "Epoch 97/500\n",
      "5984/5984 [==============================] - 2s 332us/step - loss: 0.0384 - mae: 0.1411 - val_loss: 0.0635 - val_mae: 0.1839\n",
      "Epoch 98/500\n",
      "5984/5984 [==============================] - 2s 317us/step - loss: 0.0387 - mae: 0.1418 - val_loss: 0.1114 - val_mae: 0.2568\n",
      "Epoch 99/500\n",
      "5984/5984 [==============================] - 2s 308us/step - loss: 0.0372 - mae: 0.1377 - val_loss: 0.0503 - val_mae: 0.1618\n",
      "Epoch 100/500\n",
      "5984/5984 [==============================] - 2s 306us/step - loss: 0.0379 - mae: 0.1407 - val_loss: 0.0529 - val_mae: 0.1635\n",
      "Epoch 101/500\n",
      "5984/5984 [==============================] - 2s 303us/step - loss: 0.0373 - mae: 0.1382 - val_loss: 0.0512 - val_mae: 0.1611\n",
      "Epoch 102/500\n",
      "5984/5984 [==============================] - 2s 306us/step - loss: 0.0375 - mae: 0.1394 - val_loss: 0.0518 - val_mae: 0.1622\n",
      "Epoch 103/500\n",
      "5984/5984 [==============================] - 2s 308us/step - loss: 0.0358 - mae: 0.1357 - val_loss: 0.0997 - val_mae: 0.2417\n",
      "Epoch 104/500\n",
      "5984/5984 [==============================] - 2s 310us/step - loss: 0.0357 - mae: 0.1357 - val_loss: 0.0486 - val_mae: 0.1563\n",
      "Epoch 105/500\n",
      "5984/5984 [==============================] - 2s 312us/step - loss: 0.0367 - mae: 0.1371 - val_loss: 0.0554 - val_mae: 0.1678\n",
      "Epoch 106/500\n",
      "5984/5984 [==============================] - 2s 314us/step - loss: 0.0356 - mae: 0.1348 - val_loss: 0.0482 - val_mae: 0.1563\n",
      "Epoch 107/500\n",
      "5984/5984 [==============================] - 2s 296us/step - loss: 0.0361 - mae: 0.1366 - val_loss: 0.0627 - val_mae: 0.1757\n",
      "Epoch 108/500\n",
      "5984/5984 [==============================] - 2s 285us/step - loss: 0.0349 - mae: 0.1344 - val_loss: 0.0524 - val_mae: 0.1621\n",
      "Epoch 109/500\n",
      "5984/5984 [==============================] - 2s 343us/step - loss: 0.0352 - mae: 0.1354 - val_loss: 0.0566 - val_mae: 0.1692\n",
      "Epoch 110/500\n",
      "5984/5984 [==============================] - 2s 395us/step - loss: 0.0345 - mae: 0.1337 - val_loss: 0.0546 - val_mae: 0.1663\n",
      "Train on 5984 samples, validate on 2016 samples\n",
      "Epoch 1/500\n",
      "5984/5984 [==============================] - 2s 391us/step - loss: 1.7247 - mae: 0.8802 - val_loss: 0.6469 - val_mae: 0.3929\n",
      "Epoch 2/500\n",
      "5984/5984 [==============================] - 2s 299us/step - loss: 1.1894 - mae: 0.6890 - val_loss: 0.5553 - val_mae: 0.3124\n",
      "Epoch 3/500\n",
      "5984/5984 [==============================] - 2s 349us/step - loss: 0.9687 - mae: 0.5884 - val_loss: 0.5669 - val_mae: 0.3347\n",
      "Epoch 4/500\n",
      "5984/5984 [==============================] - 2s 319us/step - loss: 0.8896 - mae: 0.5478 - val_loss: 0.5368 - val_mae: 0.3103\n",
      "Epoch 5/500\n",
      "5984/5984 [==============================] - 2s 322us/step - loss: 0.8131 - mae: 0.5110 - val_loss: 0.5077 - val_mae: 0.2942\n",
      "Epoch 6/500\n",
      "5984/5984 [==============================] - 2s 319us/step - loss: 0.7452 - mae: 0.4756 - val_loss: 0.4628 - val_mae: 0.2556\n",
      "Epoch 7/500\n",
      "5984/5984 [==============================] - 2s 318us/step - loss: 0.6960 - mae: 0.4507 - val_loss: 0.4474 - val_mae: 0.2610\n",
      "Epoch 8/500\n",
      "5984/5984 [==============================] - 2s 306us/step - loss: 0.6439 - mae: 0.4294 - val_loss: 0.4300 - val_mae: 0.2596\n",
      "Epoch 9/500\n",
      "5984/5984 [==============================] - 2s 298us/step - loss: 0.6065 - mae: 0.4156 - val_loss: 0.4149 - val_mae: 0.2623\n",
      "Epoch 10/500\n",
      "5984/5984 [==============================] - 2s 294us/step - loss: 0.5678 - mae: 0.3993 - val_loss: 0.3926 - val_mae: 0.2558\n",
      "Epoch 11/500\n",
      "5984/5984 [==============================] - 2s 298us/step - loss: 0.5317 - mae: 0.3865 - val_loss: 0.3713 - val_mae: 0.2524\n",
      "Epoch 12/500\n",
      "5984/5984 [==============================] - 2s 312us/step - loss: 0.4928 - mae: 0.3705 - val_loss: 0.3481 - val_mae: 0.2466\n",
      "Epoch 13/500\n",
      "5984/5984 [==============================] - 2s 313us/step - loss: 0.4636 - mae: 0.3638 - val_loss: 0.3328 - val_mae: 0.2509\n",
      "Epoch 14/500\n",
      "5984/5984 [==============================] - 2s 311us/step - loss: 0.4375 - mae: 0.3597 - val_loss: 0.3150 - val_mae: 0.2530\n",
      "Epoch 15/500\n",
      "5984/5984 [==============================] - 2s 308us/step - loss: 0.4111 - mae: 0.3482 - val_loss: 0.2957 - val_mae: 0.2490\n",
      "Epoch 16/500\n",
      "5984/5984 [==============================] - 2s 309us/step - loss: 0.3789 - mae: 0.3382 - val_loss: 0.2786 - val_mae: 0.2503\n",
      "Epoch 17/500\n",
      "5984/5984 [==============================] - 2s 312us/step - loss: 0.3597 - mae: 0.3328 - val_loss: 0.2659 - val_mae: 0.2535\n",
      "Epoch 18/500\n",
      "5984/5984 [==============================] - 2s 323us/step - loss: 0.3346 - mae: 0.3257 - val_loss: 0.2523 - val_mae: 0.2539\n",
      "Epoch 19/500\n",
      "5984/5984 [==============================] - 2s 318us/step - loss: 0.3125 - mae: 0.3160 - val_loss: 0.2371 - val_mae: 0.2498\n",
      "Epoch 20/500\n",
      "5984/5984 [==============================] - 2s 312us/step - loss: 0.2941 - mae: 0.3128 - val_loss: 0.2235 - val_mae: 0.2477\n",
      "Epoch 21/500\n",
      "5984/5984 [==============================] - 2s 313us/step - loss: 0.2785 - mae: 0.3123 - val_loss: 0.2131 - val_mae: 0.2481\n",
      "Epoch 22/500\n",
      "5984/5984 [==============================] - 2s 307us/step - loss: 0.2599 - mae: 0.3018 - val_loss: 0.2030 - val_mae: 0.2498\n",
      "Epoch 23/500\n",
      "5984/5984 [==============================] - 2s 322us/step - loss: 0.2437 - mae: 0.2979 - val_loss: 0.1932 - val_mae: 0.2503\n",
      "Epoch 24/500\n",
      "5984/5984 [==============================] - 2s 326us/step - loss: 0.2280 - mae: 0.2913 - val_loss: 0.1863 - val_mae: 0.2539\n",
      "Epoch 25/500\n",
      "5984/5984 [==============================] - 2s 324us/step - loss: 0.2193 - mae: 0.2900 - val_loss: 0.1774 - val_mae: 0.2516\n",
      "Epoch 26/500\n",
      "5984/5984 [==============================] - 2s 318us/step - loss: 0.2091 - mae: 0.2885 - val_loss: 0.1693 - val_mae: 0.2494\n",
      "Epoch 27/500\n",
      "5984/5984 [==============================] - 2s 316us/step - loss: 0.1978 - mae: 0.2840 - val_loss: 0.1631 - val_mae: 0.2503\n",
      "Epoch 28/500\n",
      "5984/5984 [==============================] - 2s 324us/step - loss: 0.1934 - mae: 0.2858 - val_loss: 0.1569 - val_mae: 0.2482\n",
      "Epoch 29/500\n",
      "5984/5984 [==============================] - 2s 323us/step - loss: 0.1817 - mae: 0.2787 - val_loss: 0.1516 - val_mae: 0.2479\n",
      "Epoch 30/500\n",
      "5984/5984 [==============================] - 2s 325us/step - loss: 0.1751 - mae: 0.2759 - val_loss: 0.1503 - val_mae: 0.2525\n",
      "Epoch 31/500\n",
      "5984/5984 [==============================] - 2s 313us/step - loss: 0.1668 - mae: 0.2721 - val_loss: 0.1449 - val_mae: 0.2515\n",
      "Epoch 32/500\n",
      "5984/5984 [==============================] - 2s 320us/step - loss: 0.1601 - mae: 0.2686 - val_loss: 0.1416 - val_mae: 0.2518\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(dir_data + r\"/models/orientation_SA/\", exist_ok=True)  \n",
    "cp = callbacks.ModelCheckpoint(dir_data + r\"/models/orientation_SA/model_{epoch:02d}_{val_mae:.2f}.hdf5\", monitor='val_mae', save_best_only=True)\n",
    "es = callbacks.EarlyStopping(monitor='val_mae', patience=20, restore_best_weights=True)\n",
    "define_model(X_train_SA, y_train_SA, X_val_SA, y_val_SA, es, cp)\n",
    "\n",
    "os.makedirs(dir_data + r\"/models/orientation_RA/\", exist_ok=True)  \n",
    "cp = callbacks.ModelCheckpoint(dir_data + r\"/models/orientation_RA/model_{epoch:02d}_{val_mae:.2f}.hdf5\", monitor='val_mae', save_best_only=True)\n",
    "es = callbacks.EarlyStopping(monitor='val_mae', patience=20, restore_best_weights=True)\n",
    "define_model(X_train_RA, y_train_RA, X_val_RA, y_val_RA, es, cp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec9934d05f2433ac775bd4943a80c56f88370a8daa9f676a715cc5a3d6479729"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tactip': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
